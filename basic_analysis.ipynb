{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\qjone\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Dataset path: C:\\Users\\qjone\\.cache\\kagglehub\\datasets\\rabieelkharoua\\alzheimers-disease-dataset\\versions\\1\n",
      "Files in dataset: ['alzheimers_disease_data.csv']\n",
      "+---------+---+------+---------+--------------+------------------+-------+------------------+-----------------+------------------+-----------------+-----------------------+---------------------+--------+----------+----------+------------+----------+-----------+------------------+-----------------+-----------------+------------------------+------------------+--------------------+----------------+------------------+--------------------+---------+--------------+------------------+-------------------------+-------------+---------+--------------+\n",
      "|PatientID|Age|Gender|Ethnicity|EducationLevel|               BMI|Smoking|AlcoholConsumption| PhysicalActivity|       DietQuality|     SleepQuality|FamilyHistoryAlzheimers|CardiovascularDisease|Diabetes|Depression|HeadInjury|Hypertension|SystolicBP|DiastolicBP|  CholesterolTotal|   CholesterolLDL|   CholesterolHDL|CholesterolTriglycerides|              MMSE|FunctionalAssessment|MemoryComplaints|BehavioralProblems|                 ADL|Confusion|Disorientation|PersonalityChanges|DifficultyCompletingTasks|Forgetfulness|Diagnosis|DoctorInCharge|\n",
      "+---------+---+------+---------+--------------+------------------+-------+------------------+-----------------+------------------+-----------------+-----------------------+---------------------+--------+----------+----------+------------+----------+-----------+------------------+-----------------+-----------------+------------------------+------------------+--------------------+----------------+------------------+--------------------+---------+--------------+------------------+-------------------------+-------------+---------+--------------+\n",
      "|     4751| 73|     0|        0|             2|22.927749230993864|      0| 13.29721772827684|6.327112473553353|1.3472143059081076|9.025678665766115|                      0|                    0|       1|         1|         0|           0|       142|         72|242.36683969636556|56.15089696091113|33.68256349839592|      162.18914307736603| 21.46353236431666|   6.518876973217633|               0|                 0|  1.7258834599441897|        0|             0|                 0|                        1|            0|        0|     XXXConfid|\n",
      "|     4752| 89|     0|        0|             0| 26.82768119159602|      0|4.5425238177221905|7.619884540163032|0.5187671386507053|7.151292743051223|                      0|                    0|       0|         0|         0|           0|       115|         64|231.16259501016503|193.4079955157258|79.02847731570753|      294.63090921495643|20.613267308882918|   7.118695504189474|               0|                 0|  2.5924241326736475|        0|             0|                 0|                        0|            1|        0|     XXXConfid|\n",
      "|     4753| 73|     0|        3|             1|17.795882442817113|      0| 19.55508452555359|7.844987790974517| 1.826334664579784|9.673574157961111|                      1|                    0|       0|         0|         0|           0|        99|        116| 284.1818577646338|153.3227621844376|69.77229186479597|       83.63832413899468| 7.356248624670334|   5.895077345354194|               0|                 0|   7.119547742738579|        0|             1|                 0|                        1|            0|        0|     XXXConfid|\n",
      "|     4754| 74|     1|        0|             1| 33.80081704413547|      1|12.209265546203783|8.428001350491492|  7.43560414000302|8.392553685350862|                      0|                    0|       0|         0|         0|           0|       118|        115|159.58223960561193|65.36663683521382|68.45749070794797|       277.5773575001914|13.991127243891668|   8.965106303658107|               0|                 1|    6.48122585936608|        0|             0|                 0|                        0|            0|        0|     XXXConfid|\n",
      "|     4755| 89|     0|        0|             0|20.716973826446807|      0|18.454356090619612|6.310460689360432|0.7954975089177474|5.597237677578526|                      0|                    0|       0|         0|         0|           0|        94|        117| 237.6021836280377| 92.8696998816807|56.87430466708379|       291.1987801806695|13.517608895586092|   6.045038774287464|               0|                 0|0.014691221285652034|        0|             0|                 1|                        1|            0|        0|     XXXConfid|\n",
      "+---------+---+------+---------+--------------+------------------+-------+------------------+-----------------+------------------+-----------------+-----------------------+---------------------+--------+----------+----------+------------+----------+-----------+------------------+-----------------+-----------------+------------------------+------------------+--------------------+----------------+------------------+--------------------+---------+--------------+------------------+-------------------------+-------------+---------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import kagglehub\n",
    "from pyspark.sql import SparkSession\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"AlzheimersDataset\").getOrCreate()\n",
    "\n",
    "# Download the latest version of the dataset\n",
    "dataset_path = kagglehub.dataset_download(\"rabieelkharoua/alzheimers-disease-dataset\")\n",
    "\n",
    "print(\"Dataset path:\", dataset_path)\n",
    "\n",
    "# List files in the dataset directory\n",
    "files = os.listdir(dataset_path)\n",
    "print(\"Files in dataset:\", files)\n",
    "\n",
    "# Choose the correct CSV file (replace 'your_file.csv' with the actual file name)\n",
    "csv_file = [f for f in files if f.endswith('.csv')]\n",
    "if not csv_file:\n",
    "    raise FileNotFoundError(\"No CSV file found in the dataset directory.\")\n",
    "csv_file_path = os.path.join(dataset_path, csv_file[0])\n",
    "\n",
    "# Load the CSV file into a Spark DataFrame\n",
    "df_spark = spark.read.csv(csv_file_path, header=True, inferSchema=True)\n",
    "\n",
    "# Display the first few rows\n",
    "df_spark.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_spark.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2149 entries, 0 to 2148\n",
      "Data columns (total 35 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   PatientID                  2149 non-null   int32  \n",
      " 1   Age                        2149 non-null   int32  \n",
      " 2   Gender                     2149 non-null   int32  \n",
      " 3   Ethnicity                  2149 non-null   int32  \n",
      " 4   EducationLevel             2149 non-null   int32  \n",
      " 5   BMI                        2149 non-null   float64\n",
      " 6   Smoking                    2149 non-null   int32  \n",
      " 7   AlcoholConsumption         2149 non-null   float64\n",
      " 8   PhysicalActivity           2149 non-null   float64\n",
      " 9   DietQuality                2149 non-null   float64\n",
      " 10  SleepQuality               2149 non-null   float64\n",
      " 11  FamilyHistoryAlzheimers    2149 non-null   int32  \n",
      " 12  CardiovascularDisease      2149 non-null   int32  \n",
      " 13  Diabetes                   2149 non-null   int32  \n",
      " 14  Depression                 2149 non-null   int32  \n",
      " 15  HeadInjury                 2149 non-null   int32  \n",
      " 16  Hypertension               2149 non-null   int32  \n",
      " 17  SystolicBP                 2149 non-null   int32  \n",
      " 18  DiastolicBP                2149 non-null   int32  \n",
      " 19  CholesterolTotal           2149 non-null   float64\n",
      " 20  CholesterolLDL             2149 non-null   float64\n",
      " 21  CholesterolHDL             2149 non-null   float64\n",
      " 22  CholesterolTriglycerides   2149 non-null   float64\n",
      " 23  MMSE                       2149 non-null   float64\n",
      " 24  FunctionalAssessment       2149 non-null   float64\n",
      " 25  MemoryComplaints           2149 non-null   int32  \n",
      " 26  BehavioralProblems         2149 non-null   int32  \n",
      " 27  ADL                        2149 non-null   float64\n",
      " 28  Confusion                  2149 non-null   int32  \n",
      " 29  Disorientation             2149 non-null   int32  \n",
      " 30  PersonalityChanges         2149 non-null   int32  \n",
      " 31  DifficultyCompletingTasks  2149 non-null   int32  \n",
      " 32  Forgetfulness              2149 non-null   int32  \n",
      " 33  Diagnosis                  2149 non-null   int32  \n",
      " 34  DoctorInCharge             2149 non-null   object \n",
      "dtypes: float64(12), int32(22), object(1)\n",
      "memory usage: 403.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the value counts for the column named: PatientID\n",
      "PatientID\n",
      "4751    1\n",
      "6179    1\n",
      "6193    1\n",
      "6192    1\n",
      "6191    1\n",
      "       ..\n",
      "5462    1\n",
      "5461    1\n",
      "5460    1\n",
      "5459    1\n",
      "6899    1\n",
      "Name: count, Length: 2149, dtype: int64\n",
      "These are the value counts for the column named: Age\n",
      "Age\n",
      "88    84\n",
      "68    84\n",
      "72    82\n",
      "76    81\n",
      "71    80\n",
      "90    79\n",
      "67    77\n",
      "60    74\n",
      "70    74\n",
      "66    73\n",
      "89    72\n",
      "77    72\n",
      "78    72\n",
      "84    71\n",
      "83    71\n",
      "62    70\n",
      "63    69\n",
      "80    68\n",
      "61    68\n",
      "87    68\n",
      "82    68\n",
      "73    66\n",
      "65    64\n",
      "75    64\n",
      "69    63\n",
      "64    59\n",
      "79    57\n",
      "85    57\n",
      "81    57\n",
      "74    55\n",
      "86    50\n",
      "Name: count, dtype: int64\n",
      "These are the value counts for the column named: Gender\n",
      "Gender\n",
      "1    1088\n",
      "0    1061\n",
      "Name: count, dtype: int64\n",
      "These are the value counts for the column named: Ethnicity\n",
      "Ethnicity\n",
      "0    1278\n",
      "1     454\n",
      "3     211\n",
      "2     206\n",
      "Name: count, dtype: int64\n",
      "These are the value counts for the column named: EducationLevel\n",
      "EducationLevel\n",
      "1    854\n",
      "2    636\n",
      "0    446\n",
      "3    213\n",
      "Name: count, dtype: int64\n",
      "These are the value counts for the column named: BMI\n",
      "BMI\n",
      "22.927749    1\n",
      "37.002439    1\n",
      "29.549056    1\n",
      "23.715891    1\n",
      "26.197217    1\n",
      "            ..\n",
      "20.352158    1\n",
      "36.970870    1\n",
      "28.204418    1\n",
      "26.313938    1\n",
      "33.289738    1\n",
      "Name: count, Length: 2149, dtype: int64\n",
      "These are the value counts for the column named: Smoking\n",
      "Smoking\n",
      "0    1529\n",
      "1     620\n",
      "Name: count, dtype: int64\n",
      "These are the value counts for the column named: AlcoholConsumption\n",
      "AlcoholConsumption\n",
      "13.297218    1\n",
      "12.324126    1\n",
      "0.697864     1\n",
      "12.339372    1\n",
      "6.459403     1\n",
      "            ..\n",
      "16.789335    1\n",
      "10.962042    1\n",
      "10.645084    1\n",
      "8.059143     1\n",
      "7.890703     1\n",
      "Name: count, Length: 2149, dtype: int64\n",
      "These are the value counts for the column named: PhysicalActivity\n",
      "PhysicalActivity\n",
      "6.327112    1\n",
      "2.450198    1\n",
      "2.749494    1\n",
      "5.970801    1\n",
      "0.423189    1\n",
      "           ..\n",
      "3.376786    1\n",
      "3.556076    1\n",
      "6.876926    1\n",
      "8.623144    1\n",
      "6.570993    1\n",
      "Name: count, Length: 2149, dtype: int64\n",
      "These are the value counts for the column named: DietQuality\n",
      "DietQuality\n",
      "1.347214    1\n",
      "7.014414    1\n",
      "8.522937    1\n",
      "1.625098    1\n",
      "2.315880    1\n",
      "           ..\n",
      "1.736764    1\n",
      "9.822954    1\n",
      "3.956355    1\n",
      "4.027420    1\n",
      "7.941404    1\n",
      "Name: count, Length: 2149, dtype: int64\n",
      "These are the value counts for the column named: SleepQuality\n",
      "SleepQuality\n",
      "9.025679    1\n",
      "5.303641    1\n",
      "9.988452    1\n",
      "8.944899    1\n",
      "7.014251    1\n",
      "           ..\n",
      "7.633571    1\n",
      "8.099905    1\n",
      "9.300057    1\n",
      "6.734356    1\n",
      "9.878711    1\n",
      "Name: count, Length: 2149, dtype: int64\n",
      "These are the value counts for the column named: FamilyHistoryAlzheimers\n",
      "FamilyHistoryAlzheimers\n",
      "0    1607\n",
      "1     542\n",
      "Name: count, dtype: int64\n",
      "These are the value counts for the column named: CardiovascularDisease\n",
      "CardiovascularDisease\n",
      "0    1839\n",
      "1     310\n",
      "Name: count, dtype: int64\n",
      "These are the value counts for the column named: Diabetes\n",
      "Diabetes\n",
      "0    1825\n",
      "1     324\n",
      "Name: count, dtype: int64\n",
      "These are the value counts for the column named: Depression\n",
      "Depression\n",
      "0    1718\n",
      "1     431\n",
      "Name: count, dtype: int64\n",
      "These are the value counts for the column named: HeadInjury\n",
      "HeadInjury\n",
      "0    1950\n",
      "1     199\n",
      "Name: count, dtype: int64\n",
      "These are the value counts for the column named: Hypertension\n",
      "Hypertension\n",
      "0    1829\n",
      "1     320\n",
      "Name: count, dtype: int64\n",
      "These are the value counts for the column named: SystolicBP\n",
      "SystolicBP\n",
      "155    37\n",
      "106    34\n",
      "126    34\n",
      "130    33\n",
      "165    33\n",
      "       ..\n",
      "115    16\n",
      "168    15\n",
      "123    14\n",
      "167    13\n",
      "173    11\n",
      "Name: count, Length: 90, dtype: int64\n",
      "These are the value counts for the column named: DiastolicBP\n",
      "DiastolicBP\n",
      "61     53\n",
      "62     47\n",
      "116    46\n",
      "102    46\n",
      "103    45\n",
      "64     44\n",
      "100    43\n",
      "71     43\n",
      "107    42\n",
      "87     41\n",
      "78     40\n",
      "79     40\n",
      "96     39\n",
      "106    39\n",
      "109    39\n",
      "75     38\n",
      "104    38\n",
      "112    38\n",
      "111    38\n",
      "119    38\n",
      "69     38\n",
      "93     38\n",
      "105    37\n",
      "85     37\n",
      "98     37\n",
      "94     37\n",
      "114    36\n",
      "65     36\n",
      "113    36\n",
      "108    35\n",
      "76     35\n",
      "63     35\n",
      "118    35\n",
      "115    35\n",
      "90     35\n",
      "91     34\n",
      "110    34\n",
      "74     34\n",
      "67     34\n",
      "70     34\n",
      "72     33\n",
      "95     33\n",
      "92     33\n",
      "117    33\n",
      "88     33\n",
      "83     32\n",
      "86     32\n",
      "84     32\n",
      "99     32\n",
      "82     31\n",
      "97     31\n",
      "77     31\n",
      "81     30\n",
      "101    29\n",
      "68     28\n",
      "73     28\n",
      "60     26\n",
      "66     25\n",
      "80     25\n",
      "89     23\n",
      "Name: count, dtype: int64\n",
      "These are the value counts for the column named: CholesterolTotal\n",
      "CholesterolTotal\n",
      "242.366840    1\n",
      "260.590950    1\n",
      "164.533549    1\n",
      "264.404026    1\n",
      "168.194314    1\n",
      "             ..\n",
      "191.215657    1\n",
      "192.952427    1\n",
      "293.453436    1\n",
      "197.730957    1\n",
      "283.396797    1\n",
      "Name: count, Length: 2149, dtype: int64\n",
      "These are the value counts for the column named: CholesterolLDL\n",
      "CholesterolLDL\n",
      "56.150897     1\n",
      "55.145543     1\n",
      "151.153560    1\n",
      "129.289742    1\n",
      "148.683449    1\n",
      "             ..\n",
      "108.134459    1\n",
      "183.491038    1\n",
      "142.683503    1\n",
      "173.167872    1\n",
      "92.200064     1\n",
      "Name: count, Length: 2149, dtype: int64\n",
      "These are the value counts for the column named: CholesterolHDL\n",
      "CholesterolHDL\n",
      "33.682563    1\n",
      "73.545733    1\n",
      "24.108264    1\n",
      "54.412205    1\n",
      "33.355888    1\n",
      "            ..\n",
      "62.648791    1\n",
      "47.097402    1\n",
      "58.784750    1\n",
      "91.573272    1\n",
      "81.920043    1\n",
      "Name: count, Length: 2149, dtype: int64\n",
      "These are the value counts for the column named: CholesterolTriglycerides\n",
      "CholesterolTriglycerides\n",
      "162.189143    1\n",
      "227.759321    1\n",
      "365.629832    1\n",
      "150.058612    1\n",
      "184.544823    1\n",
      "             ..\n",
      "232.687493    1\n",
      "227.711743    1\n",
      "117.950050    1\n",
      "370.682973    1\n",
      "217.396873    1\n",
      "Name: count, Length: 2149, dtype: int64\n",
      "These are the value counts for the column named: MMSE\n",
      "MMSE\n",
      "21.463532    1\n",
      "15.219490    1\n",
      "25.157864    1\n",
      "24.098345    1\n",
      "8.430877     1\n",
      "            ..\n",
      "21.986095    1\n",
      "29.118817    1\n",
      "26.837096    1\n",
      "3.765232     1\n",
      "11.114777    1\n",
      "Name: count, Length: 2149, dtype: int64\n",
      "These are the value counts for the column named: FunctionalAssessment\n",
      "FunctionalAssessment\n",
      "6.518877    1\n",
      "6.838303    1\n",
      "6.491645    1\n",
      "7.021784    1\n",
      "5.906680    1\n",
      "           ..\n",
      "4.496684    1\n",
      "3.242755    1\n",
      "3.122554    1\n",
      "7.404631    1\n",
      "6.307543    1\n",
      "Name: count, Length: 2149, dtype: int64\n",
      "These are the value counts for the column named: MemoryComplaints\n",
      "MemoryComplaints\n",
      "0    1702\n",
      "1     447\n",
      "Name: count, dtype: int64\n",
      "These are the value counts for the column named: BehavioralProblems\n",
      "BehavioralProblems\n",
      "0    1812\n",
      "1     337\n",
      "Name: count, dtype: int64\n",
      "These are the value counts for the column named: ADL\n",
      "ADL\n",
      "1.725883    1\n",
      "1.965029    1\n",
      "0.218199    1\n",
      "2.744058    1\n",
      "3.082306    1\n",
      "           ..\n",
      "6.747443    1\n",
      "6.484365    1\n",
      "4.801802    1\n",
      "9.124760    1\n",
      "8.327563    1\n",
      "Name: count, Length: 2149, dtype: int64\n",
      "These are the value counts for the column named: Confusion\n",
      "Confusion\n",
      "0    1708\n",
      "1     441\n",
      "Name: count, dtype: int64\n",
      "These are the value counts for the column named: Disorientation\n",
      "Disorientation\n",
      "0    1809\n",
      "1     340\n",
      "Name: count, dtype: int64\n",
      "These are the value counts for the column named: PersonalityChanges\n",
      "PersonalityChanges\n",
      "0    1825\n",
      "1     324\n",
      "Name: count, dtype: int64\n",
      "These are the value counts for the column named: DifficultyCompletingTasks\n",
      "DifficultyCompletingTasks\n",
      "0    1808\n",
      "1     341\n",
      "Name: count, dtype: int64\n",
      "These are the value counts for the column named: Forgetfulness\n",
      "Forgetfulness\n",
      "0    1501\n",
      "1     648\n",
      "Name: count, dtype: int64\n",
      "These are the value counts for the column named: Diagnosis\n",
      "Diagnosis\n",
      "0    1389\n",
      "1     760\n",
      "Name: count, dtype: int64\n",
      "These are the value counts for the column named: DoctorInCharge\n",
      "DoctorInCharge\n",
      "XXXConfid    2149\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "all_columns = df.columns.tolist()\n",
    "\n",
    "for column in all_columns:\n",
    "    print(f'These are the value counts for the column named: {column}')\n",
    "    print(df[column].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>EducationLevel</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>AlcoholConsumption</th>\n",
       "      <th>PhysicalActivity</th>\n",
       "      <th>DietQuality</th>\n",
       "      <th>...</th>\n",
       "      <th>FunctionalAssessment</th>\n",
       "      <th>MemoryComplaints</th>\n",
       "      <th>BehavioralProblems</th>\n",
       "      <th>ADL</th>\n",
       "      <th>Confusion</th>\n",
       "      <th>Disorientation</th>\n",
       "      <th>PersonalityChanges</th>\n",
       "      <th>DifficultyCompletingTasks</th>\n",
       "      <th>Forgetfulness</th>\n",
       "      <th>Diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2149.000000</td>\n",
       "      <td>2149.000000</td>\n",
       "      <td>2149.000000</td>\n",
       "      <td>2149.000000</td>\n",
       "      <td>2149.000000</td>\n",
       "      <td>2149.000000</td>\n",
       "      <td>2149.000000</td>\n",
       "      <td>2149.000000</td>\n",
       "      <td>2149.000000</td>\n",
       "      <td>2149.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2149.000000</td>\n",
       "      <td>2149.000000</td>\n",
       "      <td>2149.000000</td>\n",
       "      <td>2149.000000</td>\n",
       "      <td>2149.000000</td>\n",
       "      <td>2149.000000</td>\n",
       "      <td>2149.000000</td>\n",
       "      <td>2149.000000</td>\n",
       "      <td>2149.000000</td>\n",
       "      <td>2149.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5825.000000</td>\n",
       "      <td>74.908795</td>\n",
       "      <td>0.506282</td>\n",
       "      <td>0.697534</td>\n",
       "      <td>1.286645</td>\n",
       "      <td>27.655697</td>\n",
       "      <td>0.288506</td>\n",
       "      <td>10.039442</td>\n",
       "      <td>4.920202</td>\n",
       "      <td>4.993138</td>\n",
       "      <td>...</td>\n",
       "      <td>5.080055</td>\n",
       "      <td>0.208004</td>\n",
       "      <td>0.156817</td>\n",
       "      <td>4.982958</td>\n",
       "      <td>0.205212</td>\n",
       "      <td>0.158213</td>\n",
       "      <td>0.150768</td>\n",
       "      <td>0.158678</td>\n",
       "      <td>0.301536</td>\n",
       "      <td>0.353653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>620.507185</td>\n",
       "      <td>8.990221</td>\n",
       "      <td>0.500077</td>\n",
       "      <td>0.996128</td>\n",
       "      <td>0.904527</td>\n",
       "      <td>7.217438</td>\n",
       "      <td>0.453173</td>\n",
       "      <td>5.757910</td>\n",
       "      <td>2.857191</td>\n",
       "      <td>2.909055</td>\n",
       "      <td>...</td>\n",
       "      <td>2.892743</td>\n",
       "      <td>0.405974</td>\n",
       "      <td>0.363713</td>\n",
       "      <td>2.949775</td>\n",
       "      <td>0.403950</td>\n",
       "      <td>0.365026</td>\n",
       "      <td>0.357906</td>\n",
       "      <td>0.365461</td>\n",
       "      <td>0.459032</td>\n",
       "      <td>0.478214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4751.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.008851</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002003</td>\n",
       "      <td>0.003616</td>\n",
       "      <td>0.009385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001288</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5288.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.611408</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.139810</td>\n",
       "      <td>2.570626</td>\n",
       "      <td>2.458455</td>\n",
       "      <td>...</td>\n",
       "      <td>2.566281</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.342836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5825.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>27.823924</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.934412</td>\n",
       "      <td>4.766424</td>\n",
       "      <td>5.076087</td>\n",
       "      <td>...</td>\n",
       "      <td>5.094439</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.038973</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6362.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>33.869778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.157931</td>\n",
       "      <td>7.427899</td>\n",
       "      <td>7.558625</td>\n",
       "      <td>...</td>\n",
       "      <td>7.546981</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.581490</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6899.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>39.992767</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.989293</td>\n",
       "      <td>9.987429</td>\n",
       "      <td>9.998346</td>\n",
       "      <td>...</td>\n",
       "      <td>9.996467</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.999747</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         PatientID          Age       Gender    Ethnicity  EducationLevel  \\\n",
       "count  2149.000000  2149.000000  2149.000000  2149.000000     2149.000000   \n",
       "mean   5825.000000    74.908795     0.506282     0.697534        1.286645   \n",
       "std     620.507185     8.990221     0.500077     0.996128        0.904527   \n",
       "min    4751.000000    60.000000     0.000000     0.000000        0.000000   \n",
       "25%    5288.000000    67.000000     0.000000     0.000000        1.000000   \n",
       "50%    5825.000000    75.000000     1.000000     0.000000        1.000000   \n",
       "75%    6362.000000    83.000000     1.000000     1.000000        2.000000   \n",
       "max    6899.000000    90.000000     1.000000     3.000000        3.000000   \n",
       "\n",
       "               BMI      Smoking  AlcoholConsumption  PhysicalActivity  \\\n",
       "count  2149.000000  2149.000000         2149.000000       2149.000000   \n",
       "mean     27.655697     0.288506           10.039442          4.920202   \n",
       "std       7.217438     0.453173            5.757910          2.857191   \n",
       "min      15.008851     0.000000            0.002003          0.003616   \n",
       "25%      21.611408     0.000000            5.139810          2.570626   \n",
       "50%      27.823924     0.000000            9.934412          4.766424   \n",
       "75%      33.869778     1.000000           15.157931          7.427899   \n",
       "max      39.992767     1.000000           19.989293          9.987429   \n",
       "\n",
       "       DietQuality  ...  FunctionalAssessment  MemoryComplaints  \\\n",
       "count  2149.000000  ...           2149.000000       2149.000000   \n",
       "mean      4.993138  ...              5.080055          0.208004   \n",
       "std       2.909055  ...              2.892743          0.405974   \n",
       "min       0.009385  ...              0.000460          0.000000   \n",
       "25%       2.458455  ...              2.566281          0.000000   \n",
       "50%       5.076087  ...              5.094439          0.000000   \n",
       "75%       7.558625  ...              7.546981          0.000000   \n",
       "max       9.998346  ...              9.996467          1.000000   \n",
       "\n",
       "       BehavioralProblems          ADL    Confusion  Disorientation  \\\n",
       "count         2149.000000  2149.000000  2149.000000     2149.000000   \n",
       "mean             0.156817     4.982958     0.205212        0.158213   \n",
       "std              0.363713     2.949775     0.403950        0.365026   \n",
       "min              0.000000     0.001288     0.000000        0.000000   \n",
       "25%              0.000000     2.342836     0.000000        0.000000   \n",
       "50%              0.000000     5.038973     0.000000        0.000000   \n",
       "75%              0.000000     7.581490     0.000000        0.000000   \n",
       "max              1.000000     9.999747     1.000000        1.000000   \n",
       "\n",
       "       PersonalityChanges  DifficultyCompletingTasks  Forgetfulness  \\\n",
       "count         2149.000000                2149.000000    2149.000000   \n",
       "mean             0.150768                   0.158678       0.301536   \n",
       "std              0.357906                   0.365461       0.459032   \n",
       "min              0.000000                   0.000000       0.000000   \n",
       "25%              0.000000                   0.000000       0.000000   \n",
       "50%              0.000000                   0.000000       0.000000   \n",
       "75%              0.000000                   0.000000       1.000000   \n",
       "max              1.000000                   1.000000       1.000000   \n",
       "\n",
       "         Diagnosis  \n",
       "count  2149.000000  \n",
       "mean      0.353653  \n",
       "std       0.478214  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       1.000000  \n",
       "max       1.000000  \n",
       "\n",
       "[8 rows x 34 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2149 entries, 0 to 2148\n",
      "Data columns (total 35 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   PatientID                  2149 non-null   int32  \n",
      " 1   Age                        2149 non-null   int32  \n",
      " 2   Gender                     2149 non-null   int32  \n",
      " 3   Ethnicity                  2149 non-null   int32  \n",
      " 4   EducationLevel             2149 non-null   int32  \n",
      " 5   BMI                        2149 non-null   float64\n",
      " 6   Smoking                    2149 non-null   int32  \n",
      " 7   AlcoholConsumption         2149 non-null   float64\n",
      " 8   PhysicalActivity           2149 non-null   float64\n",
      " 9   DietQuality                2149 non-null   float64\n",
      " 10  SleepQuality               2149 non-null   float64\n",
      " 11  FamilyHistoryAlzheimers    2149 non-null   int32  \n",
      " 12  CardiovascularDisease      2149 non-null   int32  \n",
      " 13  Diabetes                   2149 non-null   int32  \n",
      " 14  Depression                 2149 non-null   int32  \n",
      " 15  HeadInjury                 2149 non-null   int32  \n",
      " 16  Hypertension               2149 non-null   int32  \n",
      " 17  SystolicBP                 2149 non-null   int32  \n",
      " 18  DiastolicBP                2149 non-null   int32  \n",
      " 19  CholesterolTotal           2149 non-null   float64\n",
      " 20  CholesterolLDL             2149 non-null   float64\n",
      " 21  CholesterolHDL             2149 non-null   float64\n",
      " 22  CholesterolTriglycerides   2149 non-null   float64\n",
      " 23  MMSE                       2149 non-null   float64\n",
      " 24  FunctionalAssessment       2149 non-null   float64\n",
      " 25  MemoryComplaints           2149 non-null   int32  \n",
      " 26  BehavioralProblems         2149 non-null   int32  \n",
      " 27  ADL                        2149 non-null   float64\n",
      " 28  Confusion                  2149 non-null   int32  \n",
      " 29  Disorientation             2149 non-null   int32  \n",
      " 30  PersonalityChanges         2149 non-null   int32  \n",
      " 31  DifficultyCompletingTasks  2149 non-null   int32  \n",
      " 32  Forgetfulness              2149 non-null   int32  \n",
      " 33  Diagnosis                  2149 non-null   int32  \n",
      " 34  DoctorInCharge             2149 non-null   object \n",
      "dtypes: float64(12), int32(22), object(1)\n",
      "memory usage: 403.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n",
      "Accuracy: 0.9465\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96       277\n",
      "           1       0.96      0.88      0.92       153\n",
      "\n",
      "    accuracy                           0.95       430\n",
      "   macro avg       0.95      0.93      0.94       430\n",
      "weighted avg       0.95      0.95      0.95       430\n",
      "\n",
      "                      Feature  Importance\n",
      "23       FunctionalAssessment    0.202252\n",
      "26                        ADL    0.176325\n",
      "22                       MMSE    0.128243\n",
      "24           MemoryComplaints    0.089677\n",
      "25         BehavioralProblems    0.050370\n",
      "8                 DietQuality    0.027584\n",
      "21   CholesterolTriglycerides    0.027234\n",
      "20             CholesterolHDL    0.026933\n",
      "7            PhysicalActivity    0.026467\n",
      "9                SleepQuality    0.026458\n",
      "18           CholesterolTotal    0.026181\n",
      "4                         BMI    0.025284\n",
      "19             CholesterolLDL    0.024569\n",
      "6          AlcoholConsumption    0.024220\n",
      "16                 SystolicBP    0.022663\n",
      "0                         Age    0.020805\n",
      "17                DiastolicBP    0.020467\n",
      "3              EducationLevel    0.009598\n",
      "2                   Ethnicity    0.006507\n",
      "1                      Gender    0.003646\n",
      "31              Forgetfulness    0.003572\n",
      "15               Hypertension    0.003332\n",
      "10    FamilyHistoryAlzheimers    0.003156\n",
      "5                     Smoking    0.003108\n",
      "13                 Depression    0.003008\n",
      "12                   Diabetes    0.002845\n",
      "27                  Confusion    0.002755\n",
      "30  DifficultyCompletingTasks    0.002700\n",
      "29         PersonalityChanges    0.002538\n",
      "28             Disorientation    0.002514\n",
      "11      CardiovascularDisease    0.002500\n",
      "14                 HeadInjury    0.002490\n"
     ]
    }
   ],
   "source": [
    "# Create a copy of the dataframe\n",
    "df_copy = df.copy()\n",
    "\n",
    "# Step 1: Drop uneeded columns\n",
    "df_copy = df_copy.drop(columns=(['PatientID', 'DoctorInCharge']))\n",
    "\n",
    "# Step 2: Define features and target\n",
    "X = df_copy.drop(columns='Diagnosis')\n",
    "y = df_copy['Diagnosis']\n",
    "\n",
    "# Step 3: Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Initialize the model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [200, 300, 400],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, verbose=2, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_rf = grid_search.best_estimator_\n",
    "best_rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_rf.predict(X_test)\n",
    "# Step 10: Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Additional classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# If you need to further evaluate feature importances\n",
    "feature_importances = best_rf.feature_importances_\n",
    "features = X.columns\n",
    "\n",
    "# Create a DataFrame for better readability\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape: (1719, 32)\n",
      "Test Data Shape: (430, 32)\n"
     ]
    }
   ],
   "source": [
    "# Create my df\n",
    "my_df = df_copy.copy()\n",
    "\n",
    "# Declare dcolumns to drop\n",
    "\n",
    "\n",
    "# Grab only my columns to evaluate\n",
    "my_df = my_df.drop()\n",
    "\n",
    "# Define features and target\n",
    "X = df_copy.drop(columns='Diagnosis')\n",
    "y = df_copy['Diagnosis']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# Check dimensions\n",
    "print(f\"Training Data Shape: {X_train_scaled.shape}\")\n",
    "print(f\"Test Data Shape: {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(hp):\n",
    "    nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "    # Allow kerastuner to decide activation function\n",
    "    activation = hp.Choice('activation', ['relu', 'tanh', 'sigmoid'])\n",
    "\n",
    "    # First hidden layer\n",
    "    nn_model.add(tf.keras.layers.Dense(\n",
    "        units=hp.Int('first_units', min_value=25, max_value=200, step=25),\n",
    "        activation=activation,\n",
    "        input_dim=32\n",
    "    ))\n",
    "\n",
    "    # Hidden layers (1 to 4)\n",
    "    for i in range(hp.Int('num_layers', 1, 4)):\n",
    "        units = hp.Int(f'units_{i}', min_value=35, max_value=300, step=25)\n",
    "        nn_model.add(tf.keras.layers.Dense(units, activation=activation))\n",
    "\n",
    "    # Output layer\n",
    "    nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "    # Compile with tunable optimizer\n",
    "    optimizer = hp.Choice('optimizer', ['adam', 'rmsprop', 'sgd'])\n",
    "    nn_model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "    return nn_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from .\\untitled_project\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "# Define early stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Define the Hyperband tuner\n",
    "tuner = kt.Hyperband(\n",
    "    create_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_epochs=70,  \n",
    "    hyperband_iterations=8  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 714 Complete [00h 00m 05s]\n",
      "val_accuracy: 0.8441860675811768\n",
      "\n",
      "Best val_accuracy So Far: 0.8581395149230957\n",
      "Total elapsed time: 01h 20m 18s\n"
     ]
    }
   ],
   "source": [
    "# Run the Keras Tuner search\n",
    "tuner.search(X_train_scaled, y_train, epochs=50, validation_data=(X_test_scaled, y_test), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'tanh', 'first_units': 125, 'num_layers': 4, 'units_0': 185, 'optimizer': 'rmsprop', 'units_1': 160, 'units_2': 210, 'units_3': 110, 'tuner/epochs': 24, 'tuner/initial_epoch': 8, 'tuner/bracket': 3, 'tuner/round': 2, 'tuner/trial_id': '0034'}\n",
      "{'activation': 'tanh', 'first_units': 100, 'num_layers': 4, 'units_0': 235, 'optimizer': 'rmsprop', 'units_1': 285, 'units_2': 260, 'units_3': 285, 'tuner/epochs': 24, 'tuner/initial_epoch': 8, 'tuner/bracket': 3, 'tuner/round': 2, 'tuner/trial_id': '0211'}\n",
      "{'activation': 'tanh', 'first_units': 150, 'num_layers': 3, 'units_0': 285, 'optimizer': 'adam', 'units_1': 85, 'units_2': 110, 'units_3': 160, 'tuner/epochs': 8, 'tuner/initial_epoch': 3, 'tuner/bracket': 3, 'tuner/round': 1, 'tuner/trial_id': '0272'}\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\qjone\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2066, in test_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\qjone\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2049, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\qjone\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2037, in run_step  **\n        outputs = model.test_step(data)\n    File \"c:\\Users\\qjone\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1917, in test_step\n        y_pred = self(x, training=False)\n    File \"c:\\Users\\qjone\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\qjone\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 32), found shape=(None, 8)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m top_model \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mget_best_models(\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m top_model:\n\u001b[1;32m----> 8\u001b[0m     model_loss, model_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_accuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\qjone\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filedr2ueg4r.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__test_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\qjone\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2066, in test_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\qjone\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2049, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\qjone\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2037, in run_step  **\n        outputs = model.test_step(data)\n    File \"c:\\Users\\qjone\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1917, in test_step\n        y_pred = self(x, training=False)\n    File \"c:\\Users\\qjone\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\qjone\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 32), found shape=(None, 8)\n"
     ]
    }
   ],
   "source": [
    "top_hyper = tuner.get_best_hyperparameters(3)\n",
    "for param in top_hyper:\n",
    "    print(param.values)\n",
    "\n",
    "\n",
    "top_model = tuner.get_best_models(3)\n",
    "for model in top_model:\n",
    "    model_loss, model_accuracy = model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "    print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DietQuality</th>\n",
       "      <th>SleepQuality</th>\n",
       "      <th>FamilyHistoryAlzheimers</th>\n",
       "      <th>CardiovascularDisease</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Depression</th>\n",
       "      <th>HeadInjury</th>\n",
       "      <th>Hypertension</th>\n",
       "      <th>Diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.347214</td>\n",
       "      <td>9.025679</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.518767</td>\n",
       "      <td>7.151293</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.826335</td>\n",
       "      <td>9.673574</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.435604</td>\n",
       "      <td>8.392554</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.795498</td>\n",
       "      <td>5.597238</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DietQuality  SleepQuality  FamilyHistoryAlzheimers  CardiovascularDisease  \\\n",
       "0     1.347214      9.025679                        0                      0   \n",
       "1     0.518767      7.151293                        0                      0   \n",
       "2     1.826335      9.673574                        1                      0   \n",
       "3     7.435604      8.392554                        0                      0   \n",
       "4     0.795498      5.597238                        0                      0   \n",
       "\n",
       "   Diabetes  Depression  HeadInjury  Hypertension  Diagnosis  \n",
       "0         1           1           0             0          0  \n",
       "1         0           0           0             0          0  \n",
       "2         0           0           0             0          0  \n",
       "3         0           0           0             0          0  \n",
       "4         0           0           0             0          0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create my df\n",
    "my_df = df.copy()\n",
    "\n",
    "# Grab only my columns to evaluate\n",
    "my_df = my_df.filter(items=['DietQuality', 'SleepQuality', 'FamilyHistoryAlzheimers', 'CardiovascularDisease', 'Diabetes', 'Depression', 'HeadInjury', 'Hypertension', 'Diagnosis'])\n",
    "\n",
    "my_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape: (1719, 8)\n",
      "Test Data Shape: (430, 8)\n"
     ]
    }
   ],
   "source": [
    "# Define features and target\n",
    "X = my_df.drop(columns='Diagnosis')\n",
    "y = my_df['Diagnosis']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# Check dimensions\n",
    "print(f\"Training Data Shape: {X_train_scaled.shape}\")\n",
    "print(f\"Test Data Shape: {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(hp):\n",
    "    nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "    # Allow kerastuner to decide activation function\n",
    "    activation = hp.Choice('activation', ['relu', 'tanh', 'sigmoid'])\n",
    "\n",
    "    # First hidden layer\n",
    "    nn_model.add(tf.keras.layers.Dense(\n",
    "        units=hp.Int('first_units', min_value=25, max_value=200, step=25),\n",
    "        activation=activation,\n",
    "        input_dim=8\n",
    "    ))\n",
    "\n",
    "    # Hidden layers (1 to 4)\n",
    "    for i in range(hp.Int('num_layers', 1, 4)):\n",
    "        units = hp.Int(f'units_{i}', min_value=35, max_value=300, step=25)\n",
    "        nn_model.add(tf.keras.layers.Dense(units, activation=activation))\n",
    "\n",
    "    # Output layer\n",
    "    nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "    # Compile with tunable optimizer\n",
    "    optimizer = hp.Choice('optimizer', ['adam', 'rmsprop', 'sgd'])\n",
    "    nn_model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "    return nn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted tuner directory: True\n"
     ]
    }
   ],
   "source": [
    "# Reset tuner if needed\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Define the tuner directory based on output\n",
    "tuner_dir = os.path.join(\".\", \"untitled_project\")\n",
    "\n",
    "# Delete the tuner directory\n",
    "shutil.rmtree(tuner_dir, ignore_errors=True)\n",
    "\n",
    "# Confirm deletion\n",
    "print(\"Deleted tuner directory:\", not os.path.exists(tuner_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define early stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Define the Hyperband tuner\n",
    "tuner = kt.Hyperband(\n",
    "    create_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_epochs=70,  \n",
    "    hyperband_iterations=8  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 151 Complete [00h 00m 06s]\n",
      "val_accuracy: 0.6465116143226624\n",
      "\n",
      "Best val_accuracy So Far: 0.6581395268440247\n",
      "Total elapsed time: 00h 31m 15s\n",
      "\n",
      "Search: Running Trial #152\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "sigmoid           |tanh              |activation\n",
      "50                |150               |first_units\n",
      "3                 |1                 |num_layers\n",
      "135               |235               |units_0\n",
      "rmsprop           |adam              |optimizer\n",
      "85                |135               |units_1\n",
      "35                |35                |units_2\n",
      "135               |85                |units_3\n",
      "8                 |8                 |tuner/epochs\n",
      "0                 |3                 |tuner/initial_epoch\n",
      "2                 |3                 |tuner/bracket\n",
      "0                 |1                 |tuner/round\n",
      "\n",
      "Epoch 1/8\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run the Keras Tuner search\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\qjone\\anaconda3\\envs\\dev\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:234\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    231\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[1;32m--> 234\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_run_and_update_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_end(trial)\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[1;32mc:\\Users\\qjone\\anaconda3\\envs\\dev\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:274\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 274\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_and_update_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[0;32m    275\u001b[0m         trial\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m trial_module\u001b[38;5;241m.\u001b[39mTrialStatus\u001b[38;5;241m.\u001b[39mCOMPLETED\n\u001b[0;32m    276\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\qjone\\anaconda3\\envs\\dev\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:239\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[1;32m--> 239\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_trial(trial\u001b[38;5;241m.\u001b[39mtrial_id)\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mexists(\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective\u001b[38;5;241m.\u001b[39mname\n\u001b[0;32m    242\u001b[0m     ):\n\u001b[0;32m    243\u001b[0m         \u001b[38;5;66;03m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[0;32m    244\u001b[0m         \u001b[38;5;66;03m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[0;32m    245\u001b[0m         \u001b[38;5;66;03m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[0;32m    246\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe use case of calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    248\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    254\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    255\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\qjone\\anaconda3\\envs\\dev\\lib\\site-packages\\keras_tuner\\src\\tuners\\hyperband.py:427\u001b[0m, in \u001b[0;36mHyperband.run_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    425\u001b[0m     fit_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m hp\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtuner/epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    426\u001b[0m     fit_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m hp\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtuner/initial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrun_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\qjone\\anaconda3\\envs\\dev\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py:314\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    312\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(model_checkpoint)\n\u001b[0;32m    313\u001b[0m     copied_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[1;32m--> 314\u001b[0m     obj_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_and_fit_model(trial, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcopied_kwargs)\n\u001b[0;32m    316\u001b[0m     histories\u001b[38;5;241m.\u001b[39mappend(obj_value)\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "File \u001b[1;32mc:\\Users\\qjone\\anaconda3\\envs\\dev\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py:233\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    231\u001b[0m hp \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39mhyperparameters\n\u001b[0;32m    232\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_build(hp)\n\u001b[1;32m--> 233\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhypermodel\u001b[38;5;241m.\u001b[39mfit(hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    235\u001b[0m \u001b[38;5;66;03m# Save the build config for model loading later.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmulti_backend():\n",
      "File \u001b[1;32mc:\\Users\\qjone\\anaconda3\\envs\\dev\\lib\\site-packages\\keras_tuner\\src\\engine\\hypermodel.py:149\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[1;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    126\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \n\u001b[0;32m    128\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;124;03m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\qjone\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\qjone\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\engine\\training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1805\u001b[0m ):\n\u001b[0;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\qjone\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\qjone\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\qjone\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:905\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    901\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[0;32m    902\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;66;03m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[0;32m    904\u001b[0m     \u001b[38;5;66;03m# no_variable_creation function.\u001b[39;00m\n\u001b[1;32m--> 905\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    906\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[0;32m    907\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    909\u001b[0m   bound_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\n\u001b[0;32m    910\u001b[0m       \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds\n\u001b[0;32m    911\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\qjone\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\qjone\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1325\u001b[0m     args,\n\u001b[0;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1327\u001b[0m     executing_eagerly)\n\u001b[0;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\qjone\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\qjone\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\qjone\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1501\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\qjone\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run the Keras Tuner search\n",
    "tuner.search(X_train_scaled, y_train, epochs=50, validation_data=(X_test_scaled, y_test), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_hyper = tuner.get_best_hyperparameters(3)\n",
    "for param in top_hyper:\n",
    "    print(param.values)\n",
    "\n",
    "\n",
    "top_model = tuner.get_best_models(3)\n",
    "for model in top_model:\n",
    "    model_loss, model_accuracy = model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "    print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
