{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\qjone\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>EducationLevel</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>AlcoholConsumption</th>\n",
       "      <th>PhysicalActivity</th>\n",
       "      <th>DietQuality</th>\n",
       "      <th>SleepQuality</th>\n",
       "      <th>...</th>\n",
       "      <th>FunctionalAssessment</th>\n",
       "      <th>MemoryComplaints</th>\n",
       "      <th>BehavioralProblems</th>\n",
       "      <th>ADL</th>\n",
       "      <th>Confusion</th>\n",
       "      <th>Disorientation</th>\n",
       "      <th>PersonalityChanges</th>\n",
       "      <th>DifficultyCompletingTasks</th>\n",
       "      <th>Forgetfulness</th>\n",
       "      <th>Diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>22.927749</td>\n",
       "      <td>0</td>\n",
       "      <td>13.297218</td>\n",
       "      <td>6.327112</td>\n",
       "      <td>1.347214</td>\n",
       "      <td>9.025679</td>\n",
       "      <td>...</td>\n",
       "      <td>6.518877</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.725883</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.827681</td>\n",
       "      <td>0</td>\n",
       "      <td>4.542524</td>\n",
       "      <td>7.619885</td>\n",
       "      <td>0.518767</td>\n",
       "      <td>7.151293</td>\n",
       "      <td>...</td>\n",
       "      <td>7.118696</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.592424</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>17.795882</td>\n",
       "      <td>0</td>\n",
       "      <td>19.555085</td>\n",
       "      <td>7.844988</td>\n",
       "      <td>1.826335</td>\n",
       "      <td>9.673574</td>\n",
       "      <td>...</td>\n",
       "      <td>5.895077</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.119548</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33.800817</td>\n",
       "      <td>1</td>\n",
       "      <td>12.209266</td>\n",
       "      <td>8.428001</td>\n",
       "      <td>7.435604</td>\n",
       "      <td>8.392554</td>\n",
       "      <td>...</td>\n",
       "      <td>8.965106</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.481226</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.716974</td>\n",
       "      <td>0</td>\n",
       "      <td>18.454356</td>\n",
       "      <td>6.310461</td>\n",
       "      <td>0.795498</td>\n",
       "      <td>5.597238</td>\n",
       "      <td>...</td>\n",
       "      <td>6.045039</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Gender  Ethnicity  EducationLevel        BMI  Smoking  \\\n",
       "0   73       0          0               2  22.927749        0   \n",
       "1   89       0          0               0  26.827681        0   \n",
       "2   73       0          3               1  17.795882        0   \n",
       "3   74       1          0               1  33.800817        1   \n",
       "4   89       0          0               0  20.716974        0   \n",
       "\n",
       "   AlcoholConsumption  PhysicalActivity  DietQuality  SleepQuality  ...  \\\n",
       "0           13.297218          6.327112     1.347214      9.025679  ...   \n",
       "1            4.542524          7.619885     0.518767      7.151293  ...   \n",
       "2           19.555085          7.844988     1.826335      9.673574  ...   \n",
       "3           12.209266          8.428001     7.435604      8.392554  ...   \n",
       "4           18.454356          6.310461     0.795498      5.597238  ...   \n",
       "\n",
       "   FunctionalAssessment  MemoryComplaints  BehavioralProblems       ADL  \\\n",
       "0              6.518877                 0                   0  1.725883   \n",
       "1              7.118696                 0                   0  2.592424   \n",
       "2              5.895077                 0                   0  7.119548   \n",
       "3              8.965106                 0                   1  6.481226   \n",
       "4              6.045039                 0                   0  0.014691   \n",
       "\n",
       "   Confusion  Disorientation  PersonalityChanges  DifficultyCompletingTasks  \\\n",
       "0          0               0                   0                          1   \n",
       "1          0               0                   0                          0   \n",
       "2          0               1                   0                          1   \n",
       "3          0               0                   0                          0   \n",
       "4          0               0                   1                          1   \n",
       "\n",
       "   Forgetfulness  Diagnosis  \n",
       "0              0          0  \n",
       "1              1          0  \n",
       "2              0          0  \n",
       "3              0          0  \n",
       "4              0          0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import os\n",
    "import kagglehub\n",
    "from pyspark.sql import SparkSession\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from mrmr import mrmr_classif\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "# Read in our cleaned and processed dataset\n",
    "df = pd.read_csv('Data/cleaned_alzheimers_dataset')\n",
    "\n",
    "# Check the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to Run a Random Forest Classifier combined with Grid Search to get an initial column importance rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n",
      "Accuracy: 0.9465\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96       277\n",
      "           1       0.96      0.88      0.92       153\n",
      "\n",
      "    accuracy                           0.95       430\n",
      "   macro avg       0.95      0.93      0.94       430\n",
      "weighted avg       0.95      0.95      0.95       430\n",
      "\n",
      "                      Feature  Importance\n",
      "23       FunctionalAssessment    0.202252\n",
      "26                        ADL    0.176325\n",
      "22                       MMSE    0.128243\n",
      "24           MemoryComplaints    0.089677\n",
      "25         BehavioralProblems    0.050370\n",
      "8                 DietQuality    0.027584\n",
      "21   CholesterolTriglycerides    0.027234\n",
      "20             CholesterolHDL    0.026933\n",
      "7            PhysicalActivity    0.026467\n",
      "9                SleepQuality    0.026458\n",
      "18           CholesterolTotal    0.026181\n",
      "4                         BMI    0.025284\n",
      "19             CholesterolLDL    0.024569\n",
      "6          AlcoholConsumption    0.024220\n",
      "16                 SystolicBP    0.022663\n",
      "0                         Age    0.020805\n",
      "17                DiastolicBP    0.020467\n",
      "3              EducationLevel    0.009598\n",
      "2                   Ethnicity    0.006507\n",
      "1                      Gender    0.003646\n",
      "31              Forgetfulness    0.003572\n",
      "15               Hypertension    0.003332\n",
      "10    FamilyHistoryAlzheimers    0.003156\n",
      "5                     Smoking    0.003108\n",
      "13                 Depression    0.003008\n",
      "12                   Diabetes    0.002845\n",
      "27                  Confusion    0.002755\n",
      "30  DifficultyCompletingTasks    0.002700\n",
      "29         PersonalityChanges    0.002538\n",
      "28             Disorientation    0.002514\n",
      "11      CardiovascularDisease    0.002500\n",
      "14                 HeadInjury    0.002490\n"
     ]
    }
   ],
   "source": [
    "# Create a copy of the dataframe\n",
    "df_copy = df.copy()\n",
    "\n",
    "# Step 2: Define features and target\n",
    "X = df_copy.drop(columns='Diagnosis')\n",
    "y = df_copy['Diagnosis']\n",
    "\n",
    "# Step 3: Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Initialize the model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [200, 300, 400],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, verbose=2, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_rf = grid_search.best_estimator_\n",
    "best_rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_rf.predict(X_test)\n",
    "# Step 10: Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Additional classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# If you need to further evaluate feature importances\n",
    "feature_importances = best_rf.feature_importances_\n",
    "features = X.columns\n",
    "\n",
    "# Create a DataFrame for better readability\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape: (1719, 29)\n",
      "Test Data Shape: (430, 29)\n"
     ]
    }
   ],
   "source": [
    "# Create my df\n",
    "my_df = df.copy()\n",
    "\n",
    "# MemoryComplaints, BehavioralProblems\n",
    "\n",
    "# Declare columns to drop\n",
    "columns_to_drop = ['FunctionalAssessment', 'ADL', 'MMSE']\n",
    "\n",
    "# Grab only my columns to evaluate\n",
    "my_df = my_df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Define features and target\n",
    "X = my_df.drop(columns='Diagnosis')\n",
    "y = my_df['Diagnosis']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# Check dimensions\n",
    "print(f\"Training Data Shape: {X_train_scaled.shape}\")\n",
    "print(f\"Test Data Shape: {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(hp):\n",
    "    nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "    # Allow kerastuner to decide activation function\n",
    "    activation = hp.Choice('activation', ['relu', 'tanh', 'sigmoid'])\n",
    "\n",
    "    # First hidden layer\n",
    "    nn_model.add(tf.keras.layers.Dense(\n",
    "        units=hp.Int('first_units', min_value=25, max_value=200, step=25),\n",
    "        activation=activation,\n",
    "        input_dim=29\n",
    "    ))\n",
    "\n",
    "    # Hidden layers (1 to 4)\n",
    "    for i in range(hp.Int('num_layers', 1, 4)):\n",
    "        units = hp.Int(f'units_{i}', min_value=35, max_value=300, step=25)\n",
    "        nn_model.add(tf.keras.layers.Dense(units, activation=activation))\n",
    "\n",
    "    # Output layer\n",
    "    nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "    # Compile with tunable optimizer\n",
    "    optimizer = hp.Choice('optimizer', ['adam', 'rmsprop', 'sgd'])\n",
    "    nn_model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "    return nn_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted tuner directory: True\n"
     ]
    }
   ],
   "source": [
    "# Reset tuner if needed\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Define the tuner directory based on output\n",
    "tuner_dir = os.path.join(\".\", \"untitled_project\")\n",
    "\n",
    "# Delete the tuner directory\n",
    "shutil.rmtree(tuner_dir, ignore_errors=True)\n",
    "\n",
    "# Confirm deletion\n",
    "print(\"Deleted tuner directory:\", not os.path.exists(tuner_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define early stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Define the Hyperband tuner\n",
    "tuner = kt.Hyperband(\n",
    "    create_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_epochs=70,  \n",
    "    hyperband_iterations=8  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 720 Complete [00h 00m 12s]\n",
      "val_accuracy: 0.7325581312179565\n",
      "\n",
      "Best val_accuracy So Far: 0.7488372325897217\n",
      "Total elapsed time: 01h 01m 28s\n"
     ]
    }
   ],
   "source": [
    "# Run the Keras Tuner search\n",
    "tuner.search(X_train_scaled, y_train, epochs=50, validation_data=(X_test_scaled, y_test), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'tanh', 'first_units': 25, 'num_layers': 1, 'units_0': 135, 'optimizer': 'sgd', 'units_1': 60, 'units_2': 210, 'units_3': 85, 'tuner/epochs': 24, 'tuner/initial_epoch': 0, 'tuner/bracket': 1, 'tuner/round': 0}\n",
      "{'activation': 'tanh', 'first_units': 100, 'num_layers': 4, 'units_0': 85, 'optimizer': 'adam', 'units_1': 135, 'units_2': 210, 'units_3': 185, 'tuner/epochs': 70, 'tuner/initial_epoch': 0, 'tuner/bracket': 0, 'tuner/round': 0}\n",
      "{'activation': 'relu', 'first_units': 175, 'num_layers': 3, 'units_0': 185, 'optimizer': 'adam', 'units_1': 135, 'units_2': 135, 'units_3': 260, 'tuner/epochs': 3, 'tuner/initial_epoch': 0, 'tuner/bracket': 3, 'tuner/round': 0}\n",
      "14/14 - 1s - loss: 0.5650 - accuracy: 0.7488 - 728ms/epoch - 52ms/step\n",
      "Loss: 0.5649819374084473, Accuracy: 0.7488372325897217\n",
      "14/14 - 1s - loss: 0.5568 - accuracy: 0.7488 - 673ms/epoch - 48ms/step\n",
      "Loss: 0.5567501187324524, Accuracy: 0.7488372325897217\n",
      "14/14 - 1s - loss: 0.5781 - accuracy: 0.7465 - 714ms/epoch - 51ms/step\n",
      "Loss: 0.5781014561653137, Accuracy: 0.7465116381645203\n"
     ]
    }
   ],
   "source": [
    "top_hyper = tuner.get_best_hyperparameters(3)\n",
    "for param in top_hyper:\n",
    "    print(param.values)\n",
    "\n",
    "\n",
    "top_model = tuner.get_best_models(3)\n",
    "for model in top_model:\n",
    "    model_loss, model_accuracy = model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "    print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the results of the tuner after running it with the correct column selection (i.e. dropping 'FunctionalAssessment', 'ADL', 'MMSE').\n",
    "\n",
    "```\n",
    "{'activation': 'tanh', 'first_units': 25, 'num_layers': 1, 'units_0': 135, 'optimizer': 'sgd', 'units_1': 60, 'units_2': 210, 'units_3': 85, 'tuner/epochs': 24, 'tuner/initial_epoch': 0, 'tuner/bracket': 1, 'tuner/round': 0}\n",
    "{'activation': 'tanh', 'first_units': 100, 'num_layers': 4, 'units_0': 85, 'optimizer': 'adam', 'units_1': 135, 'units_2': 210, 'units_3': 185, 'tuner/epochs': 70, 'tuner/initial_epoch': 0, 'tuner/bracket': 0, 'tuner/round': 0}\n",
    "{'activation': 'relu', 'first_units': 175, 'num_layers': 3, 'units_0': 185, 'optimizer': 'adam', 'units_1': 135, 'units_2': 135, 'units_3': 260, 'tuner/epochs': 3, 'tuner/initial_epoch': 0, 'tuner/bracket': 3, 'tuner/round': 0}\n",
    "14/14 - 1s - loss: 0.5650 - accuracy: 0.7488 - 728ms/epoch - 52ms/step\n",
    "Loss: 0.5649819374084473, Accuracy: 0.7488372325897217\n",
    "14/14 - 1s - loss: 0.5568 - accuracy: 0.7488 - 673ms/epoch - 48ms/step\n",
    "Loss: 0.5567501187324524, Accuracy: 0.7488372325897217\n",
    "14/14 - 1s - loss: 0.5781 - accuracy: 0.7465 - 714ms/epoch - 51ms/step\n",
    "Loss: 0.5781014561653137, Accuracy: 0.7465116381645203\n",
    "```\n",
    "\n",
    "This was because these seemed to be more medically focused test/assements and our goal with this model is to try and predict Alzheimers disease in patients. These initial results didnt meet the requirments. Thus, we are going to try the tuner agian while using mRMR, which is a tool that selects the top features to trian the model on? __RILEY CLARIFY PLEAES__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 48.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape: (1719, 15)\n",
      "Test Data Shape: (430, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create my df\n",
    "my_df = df.copy()\n",
    "\n",
    "# MemoryComplaints, BehavioralProblems\n",
    "\n",
    "# Declare columns to drop\n",
    "columns_to_drop = ['DoctorInCharge', 'PatientID', 'FunctionalAssessment', 'ADL', 'MMSE']\n",
    "\n",
    "# Grab only my columns to evaluate\n",
    "my_df = my_df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Define features and target\n",
    "X = my_df.drop(columns='Diagnosis')\n",
    "y = my_df['Diagnosis']\n",
    "\n",
    "# Perform mRMR feature selection to select top 15 features\n",
    "selected_features = mrmr_classif(X=X, y=y, K=15)\n",
    "\n",
    "# Keep only the selected features in X\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check dimensions\n",
    "print(f\"Training Data Shape: {X_train.shape}\")\n",
    "print(f\"Test Data Shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(hp):\n",
    "    nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "    # Allow kerastuner to decide activation function\n",
    "    activation = hp.Choice('activation', ['relu', 'tanh', 'sigmoid'])\n",
    "\n",
    "    # First hidden layer\n",
    "    nn_model.add(tf.keras.layers.Dense(\n",
    "        units=hp.Int('first_units', min_value=25, max_value=200, step=25),\n",
    "        activation=activation,\n",
    "        input_dim=15\n",
    "    ))\n",
    "\n",
    "    # Hidden layers (1 to 4)\n",
    "    for i in range(hp.Int('num_layers', 1, 4)):\n",
    "        units = hp.Int(f'units_{i}', min_value=35, max_value=300, step=25)\n",
    "        nn_model.add(tf.keras.layers.Dense(units, activation=activation))\n",
    "\n",
    "    # Output layer\n",
    "    nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "    # Compile with tunable optimizer\n",
    "    optimizer = hp.Choice('optimizer', ['adam', 'rmsprop', 'sgd'])\n",
    "    nn_model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "    return nn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted tuner directory: True\n"
     ]
    }
   ],
   "source": [
    "# Reset tuner if needed\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Define the tuner directory based on output\n",
    "tuner_dir = os.path.join(\".\", \"untitled_project\")\n",
    "\n",
    "# Delete the tuner directory\n",
    "shutil.rmtree(tuner_dir, ignore_errors=True)\n",
    "\n",
    "# Confirm deletion\n",
    "print(\"Deleted tuner directory:\", not os.path.exists(tuner_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define early stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Define the Hyperband tuner\n",
    "tuner = kt.Hyperband(\n",
    "    create_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_epochs=70,  \n",
    "    hyperband_iterations=8  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 720 Complete [00h 00m 10s]\n",
      "val_accuracy: 0.6465116143226624\n",
      "\n",
      "Best val_accuracy So Far: 0.7465116381645203\n",
      "Total elapsed time: 07h 03m 01s\n"
     ]
    }
   ],
   "source": [
    "# Run the Keras Tuner search\n",
    "tuner.search(X_train, y_train, epochs=50, validation_data=(X_test, y_test), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'sigmoid', 'first_units': 125, 'num_layers': 1, 'units_0': 235, 'optimizer': 'adam', 'units_1': 135, 'units_2': 185, 'units_3': 35, 'tuner/epochs': 70, 'tuner/initial_epoch': 24, 'tuner/bracket': 2, 'tuner/round': 2, 'tuner/trial_id': '0699'}\n",
      "{'activation': 'sigmoid', 'first_units': 200, 'num_layers': 3, 'units_0': 260, 'optimizer': 'adam', 'units_1': 185, 'units_2': 185, 'units_3': 35, 'tuner/epochs': 70, 'tuner/initial_epoch': 0, 'tuner/bracket': 0, 'tuner/round': 0}\n",
      "{'activation': 'tanh', 'first_units': 150, 'num_layers': 1, 'units_0': 285, 'optimizer': 'adam', 'units_1': 285, 'units_2': 235, 'units_3': 60, 'tuner/epochs': 70, 'tuner/initial_epoch': 0, 'tuner/bracket': 0, 'tuner/round': 0}\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n",
      "14/14 - 1s - loss: 0.5722 - accuracy: 0.7465 - 1s/epoch - 76ms/step\n",
      "Loss: 0.5721879601478577, Accuracy: 0.7465116381645203\n",
      "14/14 - 1s - loss: 0.5688 - accuracy: 0.7442 - 972ms/epoch - 69ms/step\n",
      "Loss: 0.5687639117240906, Accuracy: 0.7441860437393188\n",
      "14/14 - 1s - loss: 0.5704 - accuracy: 0.7372 - 642ms/epoch - 46ms/step\n",
      "Loss: 0.5704463720321655, Accuracy: 0.7372093200683594\n"
     ]
    }
   ],
   "source": [
    "top_hyper = tuner.get_best_hyperparameters(3)\n",
    "for param in top_hyper:\n",
    "    print(param.values)\n",
    "\n",
    "\n",
    "top_model = tuner.get_best_models(3)\n",
    "for model in top_model:\n",
    "    model_loss, model_accuracy = model.evaluate(X_test,y_test,verbose=2)\n",
    "    print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These were the results of the mRMR with the top 15 features selected tuner:\n",
    "\n",
    "```\n",
    "{'activation': 'sigmoid', 'first_units': 125, 'num_layers': 1, 'units_0': 235, 'optimizer': 'adam', 'units_1': 135, 'units_2': 185, 'units_3': 35, 'tuner/epochs': 70, 'tuner/initial_epoch': 24, 'tuner/bracket': 2, 'tuner/round': 2, 'tuner/trial_id': '0699'}\n",
    "{'activation': 'sigmoid', 'first_units': 200, 'num_layers': 3, 'units_0': 260, 'optimizer': 'adam', 'units_1': 185, 'units_2': 185, 'units_3': 35, 'tuner/epochs': 70, 'tuner/initial_epoch': 0, 'tuner/bracket': 0, 'tuner/round': 0}\n",
    "{'activation': 'tanh', 'first_units': 150, 'num_layers': 1, 'units_0': 285, 'optimizer': 'adam', 'units_1': 285, 'units_2': 235, 'units_3': 60, 'tuner/epochs': 70, 'tuner/initial_epoch': 0, 'tuner/bracket': 0, 'tuner/round': 0}\n",
    "14/14 - 1s - loss: 0.5722 - accuracy: 0.7465 - 1s/epoch - 76ms/step\n",
    "Loss: 0.5721879601478577, Accuracy: 0.7465116381645203\n",
    "14/14 - 1s - loss: 0.5688 - accuracy: 0.7442 - 972ms/epoch - 69ms/step\n",
    "Loss: 0.5687639117240906, Accuracy: 0.7441860437393188\n",
    "14/14 - 1s - loss: 0.5704 - accuracy: 0.7372 - 642ms/epoch - 46ms/step\n",
    "Loss: 0.5704463720321655, Accuracy: 0.7372093200683594\n",
    "```\n",
    "\n",
    "There doesn't seem to be a huge improvment. In fact, it seems like it did worse in some areas. Thus, we have also decided to test models with two of the columns, ADL and MMSE, to see how well our model could predict Alzheimers with one or both of these more medically relevent columns. Thus it is now time to build our models using the best hyperparameters and tweaking the feature sleection to get the most accurate and valuable models possible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 34.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape: (1719, 15)\n",
      "Test Data Shape: (430, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create my df\n",
    "my_df_1 = df.copy()\n",
    "\n",
    "# Columns included: MemoryComplaints, BehavioralProblems\n",
    "\n",
    "# Declare columns to drop\n",
    "columns_to_drop = ['FunctionalAssessment', 'ADL', 'MMSE']\n",
    "\n",
    "# Grab only my columns to evaluate\n",
    "my_df_1 = my_df_1.drop(columns=columns_to_drop)\n",
    "\n",
    "# Define features and target\n",
    "X = my_df_1.drop(columns='Diagnosis')\n",
    "y = my_df_1['Diagnosis']\n",
    "\n",
    "# Perform mRMR feature selection to select top 15 features\n",
    "selected_features = mrmr_classif(X=X, y=y, K=15)\n",
    "\n",
    "# Keep only the selected features in X\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check dimensions\n",
    "print(f\"Training Data Shape: {X_train.shape}\")\n",
    "print(f\"Test Data Shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\qjone\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\qjone\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 25/100\n",
      "WARNING:tensorflow:From c:\\Users\\qjone\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\qjone\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "54/54 [==============================] - 2s 5ms/step - loss: 0.6681 - accuracy: 0.6143\n",
      "Epoch 26/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.6560 - accuracy: 0.6446\n",
      "Epoch 27/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.6550 - accuracy: 0.6451\n",
      "Epoch 28/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6549 - accuracy: 0.6469\n",
      "Epoch 29/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6522 - accuracy: 0.6463\n",
      "Epoch 30/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.6502 - accuracy: 0.6469\n",
      "Epoch 31/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.6562 - accuracy: 0.6451\n",
      "Epoch 32/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.6518 - accuracy: 0.6469\n",
      "Epoch 33/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.6524 - accuracy: 0.6469\n",
      "Epoch 34/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.6510 - accuracy: 0.6469\n",
      "Epoch 35/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.6508 - accuracy: 0.6469\n",
      "Epoch 36/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.6531 - accuracy: 0.6469\n",
      "Epoch 37/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.6496 - accuracy: 0.6469\n",
      "Epoch 38/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6514 - accuracy: 0.6469\n",
      "Epoch 39/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6522 - accuracy: 0.6469\n",
      "Epoch 40/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6502 - accuracy: 0.6469\n",
      "Epoch 41/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6492 - accuracy: 0.6469\n",
      "Epoch 42/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6495 - accuracy: 0.6469\n",
      "Epoch 43/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.6499 - accuracy: 0.6469\n",
      "Epoch 44/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.6526 - accuracy: 0.6469\n",
      "Epoch 45/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6507 - accuracy: 0.6469\n",
      "Epoch 46/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6541 - accuracy: 0.6469\n",
      "Epoch 47/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6490 - accuracy: 0.6469\n",
      "Epoch 48/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.6493 - accuracy: 0.6469\n",
      "Epoch 49/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6495 - accuracy: 0.6469\n",
      "Epoch 50/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6522 - accuracy: 0.6469\n",
      "Epoch 51/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6488 - accuracy: 0.6469\n",
      "Epoch 52/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6513 - accuracy: 0.6469\n",
      "Epoch 53/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6515 - accuracy: 0.6469\n",
      "Epoch 54/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6499 - accuracy: 0.6469\n",
      "Epoch 55/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6481 - accuracy: 0.6469\n",
      "Epoch 56/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.6486 - accuracy: 0.6469\n",
      "Epoch 57/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6497 - accuracy: 0.6469\n",
      "Epoch 58/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6474 - accuracy: 0.6469\n",
      "Epoch 59/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6492 - accuracy: 0.6469\n",
      "Epoch 60/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6537 - accuracy: 0.6469\n",
      "Epoch 61/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6502 - accuracy: 0.6469\n",
      "Epoch 62/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.6497 - accuracy: 0.6469\n",
      "Epoch 63/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6492 - accuracy: 0.6469\n",
      "Epoch 64/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.6491 - accuracy: 0.6469\n",
      "Epoch 65/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.6482 - accuracy: 0.6469\n",
      "Epoch 66/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6495 - accuracy: 0.6469\n",
      "Epoch 67/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6463 - accuracy: 0.6469\n",
      "Epoch 68/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.6477 - accuracy: 0.6469\n",
      "Epoch 69/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.6458 - accuracy: 0.6469\n",
      "Epoch 70/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6462 - accuracy: 0.6469\n",
      "Epoch 71/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6438 - accuracy: 0.6469\n",
      "Epoch 72/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6496 - accuracy: 0.6469\n",
      "Epoch 73/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6441 - accuracy: 0.6469\n",
      "Epoch 74/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6479 - accuracy: 0.6469\n",
      "Epoch 75/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.6453 - accuracy: 0.6469\n",
      "Epoch 76/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6454 - accuracy: 0.6469\n",
      "Epoch 77/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6453 - accuracy: 0.6469\n",
      "Epoch 78/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.6434 - accuracy: 0.6469\n",
      "Epoch 79/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6475 - accuracy: 0.6469\n",
      "Epoch 80/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.6427 - accuracy: 0.6469\n",
      "Epoch 81/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.6482 - accuracy: 0.6469\n",
      "Epoch 82/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6416 - accuracy: 0.6469\n",
      "Epoch 83/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.6453 - accuracy: 0.6469\n",
      "Epoch 84/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6420 - accuracy: 0.6469\n",
      "Epoch 85/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6442 - accuracy: 0.6469\n",
      "Epoch 86/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6399 - accuracy: 0.6469\n",
      "Epoch 87/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6405 - accuracy: 0.6469\n",
      "Epoch 88/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.6417 - accuracy: 0.6469\n",
      "Epoch 89/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6366 - accuracy: 0.6469\n",
      "Epoch 90/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.6388 - accuracy: 0.6469\n",
      "Epoch 91/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.6362 - accuracy: 0.6469\n",
      "Epoch 92/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.6469\n",
      "Epoch 93/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.6446\n",
      "Epoch 94/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.6315 - accuracy: 0.6510\n",
      "Epoch 95/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6245 - accuracy: 0.6667\n",
      "Epoch 96/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.6214 - accuracy: 0.6597\n",
      "Epoch 97/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6227 - accuracy: 0.6736\n",
      "Epoch 98/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6231 - accuracy: 0.6766\n",
      "Epoch 99/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6196 - accuracy: 0.6696\n",
      "Epoch 100/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.6132 - accuracy: 0.6725\n",
      "14/14 - 0s - loss: 0.5879 - accuracy: 0.7000 - 225ms/epoch - 16ms/step\n",
      "Loss: 0.5879404544830322, Accuracy: 0.699999988079071\n"
     ]
    }
   ],
   "source": [
    "# Define the deep learning model with your specified architecture\n",
    "nn_1_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer (input layer)\n",
    "nn_1_model.add(tf.keras.layers.Dense(units=125, activation=\"sigmoid\", input_dim=15))\n",
    "nn_1_model.add(Dropout(0.2))\n",
    "\n",
    "# Add the subsequent hidden layers with the specified units\n",
    "nn_1_model.add(tf.keras.layers.Dense(units=235, activation=\"sigmoid\")) \n",
    "nn_1_model.add(Dropout(0.2))\n",
    "\n",
    "nn_1_model.add(tf.keras.layers.Dense(units=135, activation=\"sigmoid\")) \n",
    "nn_1_model.add(Dropout(0.2))\n",
    "\n",
    "nn_1_model.add(tf.keras.layers.Dense(units=185, activation=\"sigmoid\")) \n",
    "nn_1_model.add(Dropout(0.2))\n",
    "\n",
    "nn_1_model.add(tf.keras.layers.Dense(units=35, activation=\"sigmoid\")) \n",
    "nn_1_model.add(Dropout(0.2))\n",
    "\n",
    "# Add the output layer (assuming binary classification with a sigmoid activation)\n",
    "nn_1_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the Sequential model together and customize metrics\n",
    "nn_1_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model (replace X_train_scaled and y_train with your actual data)\n",
    "fit_model = nn_1_model.fit(X_train, y_train, epochs=100, initial_epoch=24)\n",
    "\n",
    "# Evaluate the model using the test data (replace X_test_scaled and y_test with your actual test data)\n",
    "model_loss, model_accuracy = nn_1_model.evaluate(X_test, y_test, verbose=2)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 30.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape: (1719, 15)\n",
      "Test Data Shape: (430, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create my df\n",
    "my_df_2 = df.copy()\n",
    "\n",
    "# Columns included: MemoryComplaints, BehavioralProblems, ADL\n",
    "# Declare columns to drop\n",
    "columns_to_drop = ['FunctionalAssessment', 'MMSE']\n",
    "\n",
    "# Grab only my columns to evaluate\n",
    "my_df_2 = my_df_2.drop(columns=columns_to_drop)\n",
    "\n",
    "# Define features and target\n",
    "X = my_df_2.drop(columns='Diagnosis')\n",
    "y = my_df_2['Diagnosis']\n",
    "\n",
    "# Perform mRMR feature selection to select top 15 features\n",
    "selected_features = mrmr_classif(X=X, y=y, K=15)\n",
    "\n",
    "# Keep only the selected features in X\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check dimensions\n",
    "print(f\"Training Data Shape: {X_train.shape}\")\n",
    "print(f\"Test Data Shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100\n",
      "54/54 [==============================] - 1s 4ms/step - loss: 0.6661 - accuracy: 0.6277\n",
      "Epoch 26/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.6571 - accuracy: 0.6405\n",
      "Epoch 27/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6538 - accuracy: 0.6440\n",
      "Epoch 28/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6550 - accuracy: 0.6428\n",
      "Epoch 29/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6556 - accuracy: 0.6463\n",
      "Epoch 30/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6599 - accuracy: 0.6457\n",
      "Epoch 31/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6507 - accuracy: 0.6469\n",
      "Epoch 32/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6534 - accuracy: 0.6469\n",
      "Epoch 33/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.6506 - accuracy: 0.6469\n",
      "Epoch 34/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6513 - accuracy: 0.6469\n",
      "Epoch 35/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.6437 - accuracy: 0.6475\n",
      "Epoch 36/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.6210 - accuracy: 0.6486\n",
      "Epoch 37/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.6014 - accuracy: 0.6731\n",
      "Epoch 38/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5936 - accuracy: 0.6672\n",
      "Epoch 39/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5817 - accuracy: 0.6940\n",
      "Epoch 40/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5806 - accuracy: 0.6806\n",
      "Epoch 41/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5822 - accuracy: 0.6847\n",
      "Epoch 42/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5769 - accuracy: 0.6952\n",
      "Epoch 43/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5837 - accuracy: 0.6806\n",
      "Epoch 44/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5719 - accuracy: 0.7010\n",
      "Epoch 45/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5708 - accuracy: 0.7074\n",
      "Epoch 46/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.5773 - accuracy: 0.7091\n",
      "Epoch 47/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5678 - accuracy: 0.7056\n",
      "Epoch 48/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5621 - accuracy: 0.7086\n",
      "Epoch 49/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5702 - accuracy: 0.6998\n",
      "Epoch 50/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5697 - accuracy: 0.7051\n",
      "Epoch 51/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5676 - accuracy: 0.6981\n",
      "Epoch 52/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5574 - accuracy: 0.7051\n",
      "Epoch 53/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5726 - accuracy: 0.7051\n",
      "Epoch 54/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5579 - accuracy: 0.7074\n",
      "Epoch 55/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5618 - accuracy: 0.7161\n",
      "Epoch 56/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5601 - accuracy: 0.7080\n",
      "Epoch 57/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5557 - accuracy: 0.7132\n",
      "Epoch 58/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.5508 - accuracy: 0.7097\n",
      "Epoch 59/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5553 - accuracy: 0.7272\n",
      "Epoch 60/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5539 - accuracy: 0.7115\n",
      "Epoch 61/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5499 - accuracy: 0.7062\n",
      "Epoch 62/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5436 - accuracy: 0.7086\n",
      "Epoch 63/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5425 - accuracy: 0.7190\n",
      "Epoch 64/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5467 - accuracy: 0.7167\n",
      "Epoch 65/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5526 - accuracy: 0.7115\n",
      "Epoch 66/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.5481 - accuracy: 0.7150\n",
      "Epoch 67/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.5467 - accuracy: 0.7237\n",
      "Epoch 68/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5361 - accuracy: 0.7283\n",
      "Epoch 69/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5379 - accuracy: 0.7347\n",
      "Epoch 70/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.5362 - accuracy: 0.7167\n",
      "Epoch 71/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5469 - accuracy: 0.7219\n",
      "Epoch 72/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5346 - accuracy: 0.7283\n",
      "Epoch 73/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5480 - accuracy: 0.7144\n",
      "Epoch 74/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5337 - accuracy: 0.7237\n",
      "Epoch 75/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5329 - accuracy: 0.7196\n",
      "Epoch 76/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.5297 - accuracy: 0.7336\n",
      "Epoch 77/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.5233 - accuracy: 0.7301\n",
      "Epoch 78/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5348 - accuracy: 0.7272\n",
      "Epoch 79/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5301 - accuracy: 0.7376\n",
      "Epoch 80/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5339 - accuracy: 0.7312\n",
      "Epoch 81/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.5189 - accuracy: 0.7318\n",
      "Epoch 82/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.5327 - accuracy: 0.7272\n",
      "Epoch 83/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.5258 - accuracy: 0.7196\n",
      "Epoch 84/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5303 - accuracy: 0.7208\n",
      "Epoch 85/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5140 - accuracy: 0.7359\n",
      "Epoch 86/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5179 - accuracy: 0.7376\n",
      "Epoch 87/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5109 - accuracy: 0.7341\n",
      "Epoch 88/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5165 - accuracy: 0.7400\n",
      "Epoch 89/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5144 - accuracy: 0.7400\n",
      "Epoch 90/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5135 - accuracy: 0.7469\n",
      "Epoch 91/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5159 - accuracy: 0.7382\n",
      "Epoch 92/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5175 - accuracy: 0.7388\n",
      "Epoch 93/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.5227 - accuracy: 0.7376\n",
      "Epoch 94/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.5211 - accuracy: 0.7388\n",
      "Epoch 95/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.5089 - accuracy: 0.7353\n",
      "Epoch 96/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5281 - accuracy: 0.7307\n",
      "Epoch 97/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5105 - accuracy: 0.7330\n",
      "Epoch 98/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.5205 - accuracy: 0.7237\n",
      "Epoch 99/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.5008 - accuracy: 0.7469\n",
      "Epoch 100/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5185 - accuracy: 0.7365\n",
      "14/14 - 0s - loss: 0.5231 - accuracy: 0.7488 - 180ms/epoch - 13ms/step\n",
      "Loss: 0.5231413841247559, Accuracy: 0.7488372325897217\n"
     ]
    }
   ],
   "source": [
    "# Define the deep learning model with your specified architecture\n",
    "nn_2_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer (input layer)\n",
    "nn_2_model.add(tf.keras.layers.Dense(units=125, activation=\"sigmoid\", input_dim=15))\n",
    "nn_2_model.add(Dropout(0.2))\n",
    "\n",
    "# Add the subsequent hidden layers with the specified units\n",
    "nn_2_model.add(tf.keras.layers.Dense(units=235, activation=\"sigmoid\")) \n",
    "nn_2_model.add(Dropout(0.2))\n",
    "\n",
    "nn_2_model.add(tf.keras.layers.Dense(units=135, activation=\"sigmoid\")) \n",
    "nn_2_model.add(Dropout(0.2))\n",
    "\n",
    "nn_2_model.add(tf.keras.layers.Dense(units=185, activation=\"sigmoid\")) \n",
    "nn_2_model.add(Dropout(0.2))\n",
    "\n",
    "nn_2_model.add(tf.keras.layers.Dense(units=35, activation=\"sigmoid\")) \n",
    "nn_2_model.add(Dropout(0.2))\n",
    "\n",
    "# Add the output layer (assuming binary classification with a sigmoid activation)\n",
    "nn_2_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the Sequential model together and customize metrics\n",
    "nn_2_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model (replace X_train_scaled and y_train with your actual data)\n",
    "fit_model = nn_2_model.fit(X_train, y_train, epochs=100, initial_epoch=24)\n",
    "\n",
    "# Evaluate the model using the test data (replace X_test_scaled and y_test with your actual test data)\n",
    "model_loss, model_accuracy = nn_2_model.evaluate(X_test, y_test, verbose=2)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 36.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape: (1719, 15)\n",
      "Test Data Shape: (430, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create my df\n",
    "my_df_3 = df.copy()\n",
    "\n",
    "# Columns included: MemoryComplaints, BehavioralProblems, MMSE\n",
    "# Declare columns to drop\n",
    "columns_to_drop = ['FunctionalAssessment', 'ADL']\n",
    "\n",
    "# Grab only my columns to evaluate\n",
    "my_df_3 = my_df_3.drop(columns=columns_to_drop)\n",
    "\n",
    "# Define features and target\n",
    "X = my_df_3.drop(columns='Diagnosis')\n",
    "y = my_df_3['Diagnosis']\n",
    "\n",
    "# Perform mRMR feature selection to select top 15 features\n",
    "selected_features = mrmr_classif(X=X, y=y, K=15)\n",
    "\n",
    "# Keep only the selected features in X\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check dimensions\n",
    "print(f\"Training Data Shape: {X_train.shape}\")\n",
    "print(f\"Test Data Shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100\n",
      "54/54 [==============================] - 1s 4ms/step - loss: 0.6819 - accuracy: 0.6161\n",
      "Epoch 26/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.6634 - accuracy: 0.6353\n",
      "Epoch 27/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6641 - accuracy: 0.6364\n",
      "Epoch 28/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6570 - accuracy: 0.6469\n",
      "Epoch 29/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6567 - accuracy: 0.6422\n",
      "Epoch 30/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6547 - accuracy: 0.6469\n",
      "Epoch 31/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6540 - accuracy: 0.6469\n",
      "Epoch 32/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6514 - accuracy: 0.6469\n",
      "Epoch 33/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6524 - accuracy: 0.6469\n",
      "Epoch 34/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6494 - accuracy: 0.6469\n",
      "Epoch 35/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6446 - accuracy: 0.6469\n",
      "Epoch 36/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6302 - accuracy: 0.6486\n",
      "Epoch 37/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6340 - accuracy: 0.6417\n",
      "Epoch 38/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6243 - accuracy: 0.6446\n",
      "Epoch 39/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.6214 - accuracy: 0.6469\n",
      "Epoch 40/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6177 - accuracy: 0.6434\n",
      "Epoch 41/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6171 - accuracy: 0.6440\n",
      "Epoch 42/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6115 - accuracy: 0.6481\n",
      "Epoch 43/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.6150 - accuracy: 0.6475\n",
      "Epoch 44/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6106 - accuracy: 0.6463\n",
      "Epoch 45/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6064 - accuracy: 0.6463\n",
      "Epoch 46/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6097 - accuracy: 0.6451\n",
      "Epoch 47/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6032 - accuracy: 0.6481\n",
      "Epoch 48/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.6154 - accuracy: 0.6463\n",
      "Epoch 49/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6028 - accuracy: 0.6481\n",
      "Epoch 50/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6036 - accuracy: 0.6498\n",
      "Epoch 51/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6100 - accuracy: 0.6463\n",
      "Epoch 52/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.5997 - accuracy: 0.6475\n",
      "Epoch 53/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6018 - accuracy: 0.6463\n",
      "Epoch 54/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6055 - accuracy: 0.6364\n",
      "Epoch 55/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6154 - accuracy: 0.6469\n",
      "Epoch 56/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6024 - accuracy: 0.6469\n",
      "Epoch 57/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5983 - accuracy: 0.6469\n",
      "Epoch 58/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.6020 - accuracy: 0.6498\n",
      "Epoch 59/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5998 - accuracy: 0.6469\n",
      "Epoch 60/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5954 - accuracy: 0.6469\n",
      "Epoch 61/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5978 - accuracy: 0.6469\n",
      "Epoch 62/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5945 - accuracy: 0.6463\n",
      "Epoch 63/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.5960 - accuracy: 0.6422\n",
      "Epoch 64/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6003 - accuracy: 0.6463\n",
      "Epoch 65/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5990 - accuracy: 0.6428\n",
      "Epoch 66/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5954 - accuracy: 0.6486\n",
      "Epoch 67/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5906 - accuracy: 0.6481\n",
      "Epoch 68/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6006 - accuracy: 0.6428\n",
      "Epoch 69/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5985 - accuracy: 0.6481\n",
      "Epoch 70/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6069 - accuracy: 0.6463\n",
      "Epoch 71/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5968 - accuracy: 0.6469\n",
      "Epoch 72/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.5894 - accuracy: 0.6463\n",
      "Epoch 73/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5980 - accuracy: 0.6463\n",
      "Epoch 74/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5916 - accuracy: 0.6486\n",
      "Epoch 75/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.5971 - accuracy: 0.6521\n",
      "Epoch 76/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5911 - accuracy: 0.6440\n",
      "Epoch 77/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5921 - accuracy: 0.6434\n",
      "Epoch 78/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5907 - accuracy: 0.6533\n",
      "Epoch 79/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5960 - accuracy: 0.6521\n",
      "Epoch 80/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5900 - accuracy: 0.6446\n",
      "Epoch 81/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5917 - accuracy: 0.6469\n",
      "Epoch 82/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5889 - accuracy: 0.6504\n",
      "Epoch 83/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5933 - accuracy: 0.6341\n",
      "Epoch 84/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5902 - accuracy: 0.6411\n",
      "Epoch 85/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5870 - accuracy: 0.6539\n",
      "Epoch 86/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.5860 - accuracy: 0.6568\n",
      "Epoch 87/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5882 - accuracy: 0.6568\n",
      "Epoch 88/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5861 - accuracy: 0.6486\n",
      "Epoch 89/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5889 - accuracy: 0.6498\n",
      "Epoch 90/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5878 - accuracy: 0.6568\n",
      "Epoch 91/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5885 - accuracy: 0.6626\n",
      "Epoch 92/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5886 - accuracy: 0.6562\n",
      "Epoch 93/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5921 - accuracy: 0.6550\n",
      "Epoch 94/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5921 - accuracy: 0.6545\n",
      "Epoch 95/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5890 - accuracy: 0.6643\n",
      "Epoch 96/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5907 - accuracy: 0.6510\n",
      "Epoch 97/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.5902 - accuracy: 0.6539\n",
      "Epoch 98/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.5815 - accuracy: 0.6719\n",
      "Epoch 99/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5868 - accuracy: 0.6556\n",
      "Epoch 100/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5835 - accuracy: 0.6626\n",
      "14/14 - 0s - loss: 0.5844 - accuracy: 0.6953 - 297ms/epoch - 21ms/step\n",
      "Loss: 0.5844082832336426, Accuracy: 0.695348858833313\n"
     ]
    }
   ],
   "source": [
    "# Define the deep learning model with your specified architecture\n",
    "nn_3_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer (input layer)\n",
    "nn_3_model.add(tf.keras.layers.Dense(units=125, activation=\"sigmoid\", input_dim=15))\n",
    "nn_3_model.add(Dropout(0.2))\n",
    "\n",
    "# Add the subsequent hidden layers with the specified units\n",
    "nn_3_model.add(tf.keras.layers.Dense(units=235, activation=\"sigmoid\")) \n",
    "nn_3_model.add(Dropout(0.2))\n",
    "\n",
    "nn_3_model.add(tf.keras.layers.Dense(units=135, activation=\"sigmoid\")) \n",
    "nn_3_model.add(Dropout(0.2))\n",
    "\n",
    "nn_3_model.add(tf.keras.layers.Dense(units=185, activation=\"sigmoid\")) \n",
    "nn_3_model.add(Dropout(0.2))\n",
    "\n",
    "nn_3_model.add(tf.keras.layers.Dense(units=35, activation=\"sigmoid\")) \n",
    "nn_3_model.add(Dropout(0.2))\n",
    "\n",
    "# Add the output layer (assuming binary classification with a sigmoid activation)\n",
    "nn_3_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the Sequential model together and customize metrics\n",
    "nn_3_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model (replace X_train_scaled and y_train with your actual data)\n",
    "fit_model = nn_3_model.fit(X_train, y_train, epochs=100, initial_epoch=24)\n",
    "\n",
    "# Evaluate the model using the test data (replace X_test_scaled and y_test with your actual test data)\n",
    "model_loss, model_accuracy = nn_3_model.evaluate(X_test, y_test, verbose=2)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 36.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape: (1719, 15)\n",
      "Test Data Shape: (430, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create my df\n",
    "my_df_4 = df.copy()\n",
    "\n",
    "# Columns included: MemoryComplaints, BehavioralProblems, MMSE, ADL\n",
    "# Declare columns to drop\n",
    "columns_to_drop = ['FunctionalAssessment']\n",
    "\n",
    "# Grab only my columns to evaluate\n",
    "my_df_4 = my_df_4.drop(columns=columns_to_drop)\n",
    "\n",
    "# Define features and target\n",
    "X = my_df_4.drop(columns='Diagnosis')\n",
    "y = my_df_4['Diagnosis']\n",
    "\n",
    "# Perform mRMR feature selection to select top 15 features\n",
    "selected_features = mrmr_classif(X=X, y=y, K=15)\n",
    "\n",
    "# Keep only the selected features in X\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check dimensions\n",
    "print(f\"Training Data Shape: {X_train.shape}\")\n",
    "print(f\"Test Data Shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100\n",
      "54/54 [==============================] - 1s 4ms/step - loss: 0.6703 - accuracy: 0.6242\n",
      "Epoch 26/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.6606 - accuracy: 0.6422\n",
      "Epoch 27/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.6591 - accuracy: 0.6440\n",
      "Epoch 28/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6502 - accuracy: 0.6469\n",
      "Epoch 29/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.6475\n",
      "Epoch 30/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.5913 - accuracy: 0.6946\n",
      "Epoch 31/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.5718 - accuracy: 0.7132\n",
      "Epoch 32/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.5560 - accuracy: 0.7341\n",
      "Epoch 33/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.5615 - accuracy: 0.7184\n",
      "Epoch 34/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.5498 - accuracy: 0.7179\n",
      "Epoch 35/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.5550 - accuracy: 0.7196\n",
      "Epoch 36/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.5325 - accuracy: 0.7353\n",
      "Epoch 37/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.5421 - accuracy: 0.7330\n",
      "Epoch 38/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.5482 - accuracy: 0.7277\n",
      "Epoch 39/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.5278 - accuracy: 0.7481\n",
      "Epoch 40/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.5344 - accuracy: 0.7376\n",
      "Epoch 41/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.5155 - accuracy: 0.7533\n",
      "Epoch 42/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.5140 - accuracy: 0.7533\n",
      "Epoch 43/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.5188 - accuracy: 0.7464\n",
      "Epoch 44/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.5034 - accuracy: 0.7493\n",
      "Epoch 45/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4986 - accuracy: 0.7568\n",
      "Epoch 46/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.5081 - accuracy: 0.7533\n",
      "Epoch 47/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4888 - accuracy: 0.7661\n",
      "Epoch 48/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4929 - accuracy: 0.7586\n",
      "Epoch 49/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4811 - accuracy: 0.7627\n",
      "Epoch 50/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.5168 - accuracy: 0.7510\n",
      "Epoch 51/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4960 - accuracy: 0.7539\n",
      "Epoch 52/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4738 - accuracy: 0.7743\n",
      "Epoch 53/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4767 - accuracy: 0.7580\n",
      "Epoch 54/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4783 - accuracy: 0.7702\n",
      "Epoch 55/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4809 - accuracy: 0.7737\n",
      "Epoch 56/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4636 - accuracy: 0.7661\n",
      "Epoch 57/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4772 - accuracy: 0.7720\n",
      "Epoch 58/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.7650\n",
      "Epoch 59/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4675 - accuracy: 0.7691\n",
      "Epoch 60/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4813 - accuracy: 0.7673\n",
      "Epoch 61/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4716 - accuracy: 0.7731\n",
      "Epoch 62/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.4779 - accuracy: 0.7644\n",
      "Epoch 63/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4692 - accuracy: 0.7824\n",
      "Epoch 64/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.4754 - accuracy: 0.7766\n",
      "Epoch 65/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4693 - accuracy: 0.7766\n",
      "Epoch 66/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.7644\n",
      "Epoch 67/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4598 - accuracy: 0.7731\n",
      "Epoch 68/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7731\n",
      "Epoch 69/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.7807\n",
      "Epoch 70/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4734 - accuracy: 0.7842\n",
      "Epoch 71/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4527 - accuracy: 0.7731\n",
      "Epoch 72/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4521 - accuracy: 0.7871\n",
      "Epoch 73/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.7818\n",
      "Epoch 74/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4469 - accuracy: 0.7801\n",
      "Epoch 75/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.7871\n",
      "Epoch 76/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4521 - accuracy: 0.7760\n",
      "Epoch 77/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.7784\n",
      "Epoch 78/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4481 - accuracy: 0.7720\n",
      "Epoch 79/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4443 - accuracy: 0.7772\n",
      "Epoch 80/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.4492 - accuracy: 0.7696\n",
      "Epoch 81/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.7755\n",
      "Epoch 82/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4470 - accuracy: 0.7795\n",
      "Epoch 83/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4523 - accuracy: 0.7784\n",
      "Epoch 84/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4528 - accuracy: 0.7772\n",
      "Epoch 85/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4462 - accuracy: 0.7766\n",
      "Epoch 86/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.7848\n",
      "Epoch 87/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.7917\n",
      "Epoch 88/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4507 - accuracy: 0.7737\n",
      "Epoch 89/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4506 - accuracy: 0.7743\n",
      "Epoch 90/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.7807\n",
      "Epoch 91/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.7760\n",
      "Epoch 92/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.7865\n",
      "Epoch 93/100\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.4469 - accuracy: 0.7749\n",
      "Epoch 94/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.7795\n",
      "Epoch 95/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.7818\n",
      "Epoch 96/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.7795\n",
      "Epoch 97/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7946\n",
      "Epoch 98/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.7830\n",
      "Epoch 99/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4391 - accuracy: 0.7818\n",
      "Epoch 100/100\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.7830\n",
      "14/14 - 0s - loss: 0.4524 - accuracy: 0.7744 - 171ms/epoch - 12ms/step\n",
      "Loss: 0.4524311423301697, Accuracy: 0.7744185924530029\n"
     ]
    }
   ],
   "source": [
    "# Define the deep learning model with your specified architecture\n",
    "nn_4_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the first layer (input layer)\n",
    "nn_4_model.add(tf.keras.layers.Dense(units=125, activation=\"sigmoid\", input_dim=15))\n",
    "nn_4_model.add(Dropout(0.2))\n",
    "\n",
    "# Add the subsequent hidden layers with the specified units\n",
    "nn_4_model.add(tf.keras.layers.Dense(units=235, activation=\"sigmoid\")) \n",
    "nn_4_model.add(Dropout(0.2))\n",
    "\n",
    "nn_4_model.add(tf.keras.layers.Dense(units=135, activation=\"sigmoid\")) \n",
    "nn_4_model.add(Dropout(0.2))\n",
    "\n",
    "nn_4_model.add(tf.keras.layers.Dense(units=185, activation=\"sigmoid\")) \n",
    "nn_4_model.add(Dropout(0.2))\n",
    "\n",
    "nn_4_model.add(tf.keras.layers.Dense(units=35, activation=\"sigmoid\")) \n",
    "nn_4_model.add(Dropout(0.2))\n",
    "\n",
    "# Add the output layer (assuming binary classification with a sigmoid activation)\n",
    "nn_4_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the Sequential model together and customize metrics\n",
    "nn_4_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model (replace X_train_scaled and y_train with your actual data)\n",
    "fit_model = nn_4_model.fit(X_train, y_train, epochs=100, initial_epoch=24)\n",
    "\n",
    "# Evaluate the model using the test data (replace X_test_scaled and y_test with your actual test data)\n",
    "model_loss, model_accuracy = nn_4_model.evaluate(X_test, y_test, verbose=2)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the results of each model:\n",
    "\n",
    "Model with both ADL and MMSE removed:\n",
    "```\n",
    "14/14 - 0s - loss: 0.5879 - accuracy: 0.7000 - 225ms/epoch - 16ms/step\n",
    "Loss: 0.5879404544830322, Accuracy: 0.699999988079071\n",
    "```\n",
    "\n",
    "Model with MMSE removed:\n",
    "```\n",
    "14/14 - 0s - loss: 0.5231 - accuracy: 0.7488 - 180ms/epoch - 13ms/step\n",
    "Loss: 0.5231413841247559, Accuracy: 0.7488372325897217\n",
    "```\n",
    "\n",
    "Model with ADL removed:\n",
    "```\n",
    "14/14 - 0s - loss: 0.5844 - accuracy: 0.6953 - 297ms/epoch - 21ms/step\n",
    "Loss: 0.5844082832336426, Accuracy: 0.695348858833313\n",
    "```\n",
    "\n",
    "Model with both ADL and MMSE included:\n",
    "```\n",
    "14/14 - 0s - loss: 0.4524 - accuracy: 0.7744 - 171ms/epoch - 12ms/step\n",
    "Loss: 0.4524311423301697, Accuracy: 0.7744185924530029\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
